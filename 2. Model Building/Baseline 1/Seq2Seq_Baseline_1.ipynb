{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Seq2Seq Baseline 1.ipynb",
   "provenance": [],
   "collapsed_sections": [
    "YzpEonV8VJQs"
   ]
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "##Load Data"
   ],
   "metadata": {
    "id": "yDP2W7CxcIMl"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eH462Xp7aR6z",
    "outputId": "2873edd6-a492-46b9-cbd6-ba8a050f5551"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\r\n",
      "From: https://drive.google.com/uc?id=1OgYbPfXFAv3TbwP1Qcwt_CC9cVWSJaco\r\n",
      "To: /home/dabestevanzzacc/indosum.tar.gz\r\n",
      "100%|███████████████████████████████████████| 96.0M/96.0M [00:00<00:00, 165MB/s]\r\n"
     ]
    }
   ],
   "source": [
    "!gdown 1OgYbPfXFAv3TbwP1Qcwt_CC9cVWSJaco"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import tarfile\n",
    "\n",
    "with tarfile.open('indosum.tar.gz') as tar:\n",
    "    tar.extractall()\n",
    "    tar.close()"
   ],
   "metadata": {
    "id": "Gp5Y4jhqcM62"
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "BASE_PATH = './indosum'\n",
    "indosum = {\n",
    "    'train': [],\n",
    "    'dev': [],\n",
    "    'test': []\n",
    "}\n",
    "\n",
    "for json_file in os.listdir('indosum'):\n",
    "    if json_file.endswith('.jsonl'):\n",
    "        split, fold, ext = json_file.split('.')\n",
    "        file_path = os.path.join(BASE_PATH, json_file)\n",
    "        \n",
    "        with open(file_path, 'r') as json_file:\n",
    "            json_list = list(json_file)\n",
    "            for json_str in json_list:\n",
    "                result = json.loads(json_str)\n",
    "                indosum[split].append(result)\n",
    "            \n",
    "\n",
    "with open('indosum.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(indosum, f, ensure_ascii=False, indent=2)\n",
    "    "
   ],
   "metadata": {
    "id": "xLwnY-jOd6fQ"
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import re\n",
    "\n",
    "def add_start_end_sequence(summary):\n",
    "    summary = 'sostok ' + summary + ' eostok'\n",
    "    return summary\n",
    "\n",
    "def convert_to_words(news_file, to_article=False):\n",
    "    content_words = []\n",
    "    for paragraph in news_file['paragraphs']:\n",
    "        for sentence in paragraph:\n",
    "            for word in sentence:\n",
    "                if re.match('[A-Za-z0-9]+', word):\n",
    "                    word = str(word).lower()\n",
    "                    content_words.append(word) \n",
    "\n",
    "    summary_words = []\n",
    "    for sentence in news_file['summary']:\n",
    "        for word in sentence:\n",
    "            if re.match('[A-Za-z0-9]+', word):\n",
    "                word = str(word).lower()\n",
    "                summary_words.append(word)\n",
    "\n",
    "    content_words = ' '.join(content_words)\n",
    "    summary_words = ' '.join(summary_words)\n",
    "\n",
    "    summary_words = add_start_end_sequence(summary_words)\n",
    "    \n",
    "    news_file['paragraphs'] = content_words\n",
    "    news_file['summary'] = summary_words"
   ],
   "metadata": {
    "id": "LhMPRe2LkFYi"
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for split in indosum.keys():\n",
    "    for news in indosum[split]:\n",
    "        convert_to_words(news)"
   ],
   "metadata": {
    "id": "ps7s8-FLeg5J"
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(indosum['dev'][5]['paragraphs'])\n",
    "print(indosum['dev'][5]['summary'])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QuaX8z_FpCRx",
    "outputId": "ffb9265e-2f96-4b2c-8d13-b911588fec1f"
   },
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "carlton cole yang pernah memperkuat west ham united sudah tiba di kantor pt persib bandung bermartabat untuk menjadi bagian persib bandung mengarungi kompetisi liga 1 2017 mantan striker tim nasional inggris hasil didikan akademi chelsea itu merupakan rekrutan masif kedua maung bandung setelah gelandang asal ghana michael essien yang pernah merumput bersama chelsea real madrid dan ac milan simak juga persib pastikan incar cole ada kabar bahwa bomber berusia 33 tahun itu akan mengikuti latihan bersama pangeran biru hari ini juga pelatih djadjang nurdjaman sebelumnya pernah menyatakan memang ingin mendatangkan striker asing menyusul cedera panjang sergio van dijk karier cole memang telah surut di inggris dan pindah ke celtic pada 2015 kemudian ia membela sacramento republic pada tahun lalu kehadiran cole diyakini bakal menambah pamor persib yang sudah mendunia usai perekrutan essien simak juga djadjang abaikan statistik cole pengoleksi tujuh caps internasional inggris dalam rentang 2009 2010 ini akan menggunakan nomor punggung 12 di persib hingga berita ini diturunkan belum ada detail kesepakatan yang diumumkan manajemen tim\n",
      "sostok carlton cole yang pernah memperkuat west ham united sudah tiba di kantor pt persib bandung bermartabat untuk menjadi bagian persib bandung mengarungi kompetisi liga 1 2017 mantan striker tim nasional inggris hasil didikan akademi chelsea itu merupakan rekrutan masif kedua maung bandung setelah gelandang asal ghana michael essien yang pernah merumput bersama chelsea real madrid dan ac eostok\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_words_distribution(dataset_dict):\n",
    "    content_count = []\n",
    "    summary_count = []\n",
    "\n",
    "    for split in dataset_dict.keys():\n",
    "        for news in dataset_dict[split]:\n",
    "            content_word_count = len(news['paragraphs'].split(' '))\n",
    "            summary_word_count = len(news['summary'].split(' '))\n",
    "            content_count.append(content_word_count)\n",
    "            summary_count.append(summary_word_count)\n",
    "\n",
    "    average_length = pd.DataFrame() \n",
    "\n",
    "    average_length['content'] = content_count\n",
    "    average_length['summary'] = summary_count\n",
    "\n",
    "    average_length.hist(bins = 5)\n",
    "    plt.show()\n",
    "    return average_length\n",
    "\n",
    "average_length = visualize_words_distribution(indosum)          "
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "hUTwNs2Cj7sv",
    "outputId": "71800404-21a2-4b8e-8780-1a5cb79108e4"
   },
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def count_words_length_percentage(max_len, length_list):\n",
    "    cnt = 0\n",
    "    for length in length_list:\n",
    "        if length <= max_len:\n",
    "            cnt = cnt + 1\n",
    "    return cnt / len(length_list)\n",
    "\n",
    "max_len_content = 600\n",
    "max_len_summary = 65\n",
    "\n",
    "print(count_words_length_percentage(max_len_content, average_length['content']))\n",
    "print(count_words_length_percentage(max_len_summary, average_length['summary']))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qwXTi8sPoxMB",
    "outputId": "80b7e579-d751-4a4c-a208-1b1f4d6e1984"
   },
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9818791946308725\n",
      "0.944710770214126\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "indosum_new = {\n",
    "    'train': [],\n",
    "    'dev': [],\n",
    "    'test': []\n",
    "}\n",
    "\n",
    "for split in indosum_new.keys():\n",
    "    for news in indosum[split]:\n",
    "        content_len = len(news['paragraphs'].split(' '))\n",
    "        summary_len = len(news['summary'].split(' '))\n",
    "        if (content_len <= max_len_content) and (summary_len <= max_len_summary):\n",
    "            indosum_new[split].append(news)"
   ],
   "metadata": {
    "id": "UGVylCFUpwTx"
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "average_length_new = visualize_words_distribution(indosum_new)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "zgg-KfTKp5x5",
    "outputId": "82a706b6-c2cd-4f94-d0e2-d9423b1db881"
   },
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "##Split Train, Dev, Test"
   ],
   "metadata": {
    "id": "UMG1mbXRqZ4y"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "X = {\n",
    "    'train': [],\n",
    "     'dev': [],\n",
    "     'test': []\n",
    "}\n",
    "for split in indosum_new.keys():\n",
    "    for news in indosum_new[split]:\n",
    "        X[split].append(news['paragraphs'])\n",
    "\n",
    "y = {\n",
    "    'train': [],\n",
    "     'dev': [],\n",
    "     'test': []\n",
    "}\n",
    "for split in indosum_new.keys():\n",
    "    for news in indosum_new[split]:\n",
    "        y[split].append(news['summary'])"
   ],
   "metadata": {
    "id": "JnG2JJlsp9Oc"
   },
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "X_train, X_dev, X_test = X['train'], X['dev'], X['test']\n",
    "y_train, y_dev, y_test = y['train'], y['dev'], y['test']"
   ],
   "metadata": {
    "id": "6lSxUZRSqeni"
   },
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "##(Experimental) Word Embedding"
   ],
   "metadata": {
    "id": "YzpEonV8VJQs"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#!pip install fasttext"
   ],
   "metadata": {
    "id": "nhy2OrhwVLx6"
   },
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#import fasttext\n",
    "#import fasttext.util\n",
    " \n",
    "#fasttext.util.download_model('id', if_exists='ignore')"
   ],
   "metadata": {
    "id": "8qDsnB3DV1Op"
   },
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#ft = fasttext.load_model(\"cc.id.300.bin\")\n",
    "#ft.get_dimension()"
   ],
   "metadata": {
    "id": "5wQehvJ-WKCD"
   },
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#fasttext.util.reduce_model(ft, 100)\n",
    "#ft.get_dimension()"
   ],
   "metadata": {
    "id": "awIkv3rTNjKG"
   },
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Tokenization"
   ],
   "metadata": {
    "id": "PSzNepwMqgxz"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Tokenize the text to get the vocab count \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "# Prepare a tokenizer on training data\n",
    "x_tokenizer = Tokenizer() \n",
    "x_tokenizer.fit_on_texts(np.array(X_train))"
   ],
   "metadata": {
    "id": "tmeEGgnaqmOu"
   },
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def count_rare_words(threshold, tokenizer):\n",
    "    cnt = 0\n",
    "    tot_cnt = 0\n",
    "\n",
    "    for key, value in tokenizer.word_counts.items():\n",
    "        tot_cnt = tot_cnt + 1\n",
    "        if value < threshold:\n",
    "            cnt = cnt + 1\n",
    "    \n",
    "    print('Threshold: {}'.format(threshold))\n",
    "    print(\"% of rare words in vocabulary: \", (cnt / tot_cnt) * 100)\n",
    "\n",
    "    return cnt, tot_cnt\n",
    "\n",
    "cnt, tot_cnt = count_rare_words(10, x_tokenizer)"
   ],
   "metadata": {
    "id": "W2nrFoBKqoZX",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "c66d4597-63b2-4695-c942-62c9915657c4"
   },
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 10\n",
      "% of rare words in vocabulary:  54.2548022094626\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Prepare a tokenizer, again -- by not considering the rare words\n",
    "x_tokenizer = Tokenizer(num_words = tot_cnt - cnt) \n",
    "x_tokenizer.fit_on_texts(np.array(X_train))\n",
    "\n",
    "# Convert text sequences to integer sequences \n",
    "x_train_seq = x_tokenizer.texts_to_sequences(X_train) \n",
    "x_dev_seq = x_tokenizer.texts_to_sequences(X_dev)\n",
    "x_test_seq = x_tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "# Pad zero upto maximum length\n",
    "x_train = pad_sequences(x_train_seq,  maxlen=max_len_content, padding='post')\n",
    "x_dev = pad_sequences(x_dev_seq, maxlen=max_len_content, padding='post')\n",
    "x_test = pad_sequences(x_test_seq,  maxlen=max_len_content, padding='post')\n",
    "\n",
    "# Size of vocabulary (+1 for padding token)\n",
    "x_vocab = x_tokenizer.num_words + 1\n",
    "\n",
    "print(\"Size of vocabulary in X = {}\".format(x_vocab))"
   ],
   "metadata": {
    "id": "OUeET2eaqxL1",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "7fec286f-d372-4027-cbe4-f708d9a6cd01"
   },
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of vocabulary in X = 46130\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Prepare a tokenizer on test data\n",
    "y_tokenizer = Tokenizer() \n",
    "y_tokenizer.fit_on_texts(np.array(y_train))\n",
    "\n",
    "cnt_test, tot_cnt_test = count_rare_words(10, y_tokenizer)"
   ],
   "metadata": {
    "id": "AxBuCLwgrHou",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "51addfde-1769-4868-e7ab-7c4dc3fe318a"
   },
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 10\n",
      "% of rare words in vocabulary:  56.45501551189245\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Prepare a tokenizer, again -- by not considering the rare words\n",
    "y_tokenizer = Tokenizer(num_words = tot_cnt_test - cnt_test) \n",
    "y_tokenizer.fit_on_texts(np.array(y_train))\n",
    "\n",
    "# Convert text sequences to integer sequences \n",
    "y_train_seq = y_tokenizer.texts_to_sequences(y_train) \n",
    "y_dev_seq = y_tokenizer.texts_to_sequences(y_dev)\n",
    "y_test_seq = y_tokenizer.texts_to_sequences(y_test)\n",
    "\n",
    "# Pad zero upto maximum length\n",
    "y_train = pad_sequences(y_train_seq,  maxlen=max_len_summary, padding='post')\n",
    "y_dev = pad_sequences(y_dev_seq, maxlen=max_len_summary, padding='post')\n",
    "y_test = pad_sequences(y_test_seq,  maxlen=max_len_summary, padding='post')\n",
    "\n",
    "# Size of vocabulary (+1 for padding token)\n",
    "y_vocab = y_tokenizer.num_words + 1\n",
    "\n",
    "print(\"Size of vocabulary in X = {}\".format(y_vocab))"
   ],
   "metadata": {
    "id": "pJlpQBcnrMs4",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "c75452d2-286a-4b4a-8a63-f3230571cfea"
   },
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of vocabulary in X = 21055\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, \\\n",
    "    Concatenate, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ],
   "metadata": {
    "id": "vltBdmbNrPCq"
   },
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "latent_dim = 300\n",
    "embedding_dim = 300\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(max_len_content, ))\n",
    "\n",
    "# Embedding layer\n",
    "enc_emb = Embedding(x_vocab, embedding_dim,\n",
    "                    trainable=True)(encoder_inputs)\n",
    "\n",
    "# Encoder LSTM 1\n",
    "encoder_lstm1 = LSTM(latent_dim, return_sequences=True,\n",
    "                     return_state=True, dropout=0.4,\n",
    "                     recurrent_dropout=0)\n",
    "(encoder_output1, state_h1, state_c1) = encoder_lstm1(enc_emb)\n",
    "\n",
    "# Encoder LSTM 2\n",
    "encoder_lstm2 = LSTM(latent_dim, return_sequences=True,\n",
    "                     return_state=True, dropout=0.4,\n",
    "                     recurrent_dropout=0)\n",
    "(encoder_output2, state_h2, state_c2) = encoder_lstm2(encoder_output1)\n",
    "\n",
    "# Encoder LSTM 3\n",
    "encoder_lstm3 = LSTM(latent_dim, return_state=True,\n",
    "                     return_sequences=True, dropout=0.4,\n",
    "                     recurrent_dropout=0)\n",
    "(encoder_outputs, state_h, state_c) = encoder_lstm3(encoder_output2)\n",
    "\n",
    "# Set up the decoder, using encoder_states as the initial state\n",
    "decoder_inputs = Input(shape=(None, ))\n",
    "\n",
    "# Embedding layer\n",
    "dec_emb_layer = Embedding(y_vocab, embedding_dim, trainable=True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# Decoder LSTM\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True,\n",
    "                    return_state=True, dropout=0.4,\n",
    "                    recurrent_dropout=0)\n",
    "(decoder_outputs, decoder_fwd_state, decoder_back_state) = \\\n",
    "    decoder_lstm(dec_emb, initial_state=[state_h, state_c])\n",
    "\n",
    "# Dense layer\n",
    "decoder_dense = TimeDistributed(Dense(y_vocab, activation='softmax'))\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.summary()"
   ],
   "metadata": {
    "id": "cbZCWNTGrVjA",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "e188edee-7d94-4ccf-cad4-1cddc780353e"
   },
   "execution_count": 27,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-04 14:39:43.992931: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2022-06-04 14:39:43.993038: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: instance-machine-learning\n",
      "2022-06-04 14:39:43.993052: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: instance-machine-learning\n",
      "2022-06-04 14:39:43.994113: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 470.57.2\n",
      "2022-06-04 14:39:43.994187: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 470.57.2\n",
      "2022-06-04 14:39:43.994195: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 470.57.2\n",
      "2022-06-04 14:39:43.996527: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 600)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 600, 300)     13839000    ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, 600, 300),   721200      ['embedding[0][0]']              \n",
      "                                 (None, 300),                                                     \n",
      "                                 (None, 300)]                                                     \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, 600, 300),   721200      ['lstm[0][0]']                   \n",
      "                                 (None, 300),                                                     \n",
      "                                 (None, 300)]                                                     \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, None, 300)    6316500     ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)                  [(None, 600, 300),   721200      ['lstm_1[0][0]']                 \n",
      "                                 (None, 300),                                                     \n",
      "                                 (None, 300)]                                                     \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)                  [(None, None, 300),  721200      ['embedding_1[0][0]',            \n",
      "                                 (None, 300),                     'lstm_2[0][1]',                 \n",
      "                                 (None, 300)]                     'lstm_2[0][2]']                 \n",
      "                                                                                                  \n",
      " time_distributed (TimeDistribu  (None, None, 21055)  6337555    ['lstm_3[0][0]']                 \n",
      " ted)                                                                                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 29,377,855\n",
      "Trainable params: 29,377,855\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3)"
   ],
   "metadata": {
    "id": "pFPkJKedr0CK"
   },
   "execution_count": 28,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "history = model.fit(\n",
    "    [x_train, y_train[:, :-1]],\n",
    "    y_train.reshape(y_train.shape[0], y_train.shape[1], 1)[:, 1:],\n",
    "    epochs=50,\n",
    "    callbacks=[es],\n",
    "    batch_size=128,\n",
    "    validation_data=([x_dev, y_dev[:, :-1]],\n",
    "                     y_dev.reshape(y_dev.shape[0], y_dev.shape[1], 1)[:, 1:]),\n",
    "    )"
   ],
   "metadata": {
    "id": "2rKZ9CJJtTlm",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "bcf1b25a-c9d9-4d3f-a559-dd3f308ce58e"
   },
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-04 14:42:47.762884: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 158935200 exceeds 10% of free system memory.\n",
      "2022-06-04 14:42:50.496994: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at list_kernels.h:220 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[600,128,300] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nOOM when allocating tensor with shape[600,128,300] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[{{node TensorArrayV2Stack/TensorListStack}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[model/lstm/PartitionedCall]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_11160]",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mResourceExhaustedError\u001B[0m                    Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_17345/3319134407.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      6\u001B[0m     \u001B[0mbatch_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m128\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m     validation_data=([x_dev, y_dev[:, :-1]],\n\u001B[0;32m----> 8\u001B[0;31m                      y_dev.reshape(y_dev.shape[0], y_dev.shape[1], 1)[:, 1:]),\n\u001B[0m\u001B[1;32m      9\u001B[0m     )\n",
      "\u001B[0;32m/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     65\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# pylint: disable=broad-except\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     66\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 67\u001B[0;31m       \u001B[0;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwith_traceback\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfiltered_tb\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     68\u001B[0m     \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     69\u001B[0m       \u001B[0;32mdel\u001B[0m \u001B[0mfiltered_tb\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001B[0m in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     53\u001B[0m     \u001B[0mctx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     54\u001B[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001B[0;32m---> 55\u001B[0;31m                                         inputs, attrs, num_outputs)\n\u001B[0m\u001B[1;32m     56\u001B[0m   \u001B[0;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     57\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mname\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mResourceExhaustedError\u001B[0m: Graph execution error:\n\nOOM when allocating tensor with shape[600,128,300] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[{{node TensorArrayV2Stack/TensorListStack}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[model/lstm/PartitionedCall]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_11160]"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "##Save Model"
   ],
   "metadata": {
    "id": "gPQ996jQbgbt"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model.save('baseline_1a')  "
   ],
   "metadata": {
    "id": "vXJHsRAhtYR3",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "7a90a189-dd02-4632-92a5-8a2b13e972d4"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!zip -r /content/baseline_1a.zip /content/baseline_1a/"
   ],
   "metadata": {
    "id": "sQxhkfLmZ1GN"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ],
   "metadata": {
    "id": "DBmYpsq35GCf",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "outputId": "ea66ef7b-2e72-477a-fb48-d062ab7e8c12"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "reverse_target_word_index = y_tokenizer.index_word\n",
    "reverse_source_word_index = x_tokenizer.index_word\n",
    "target_word_index = y_tokenizer.word_index"
   ],
   "metadata": {
    "id": "Vy4_uowj5Qrr"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs,\n",
    "                      state_h, state_c])\n",
    "\n",
    "# Decoder setup\n",
    "\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(latent_dim, ))\n",
    "decoder_state_input_c = Input(shape=(latent_dim, ))\n",
    "decoder_hidden_state_input = Input(shape=(max_len_content, latent_dim))\n",
    "\n",
    "# Get the embeddings of the decoder sequence\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "(decoder_outputs2, state_h2, state_c2) = decoder_lstm(dec_emb2,\n",
    "        initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "\n",
    "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model([decoder_inputs] + [decoder_hidden_state_input,\n",
    "                      decoder_state_input_h, decoder_state_input_c],\n",
    "                      [decoder_outputs2] + [state_h2, state_c2])"
   ],
   "metadata": {
    "id": "25Cas1ZB5UoH"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def decode_sequence(input_seq):\n",
    "\n",
    "    # Encode the input as state vectors.\n",
    "    (e_out, e_h, e_c) = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1\n",
    "    target_seq = np.zeros((1, 1))\n",
    "\n",
    "    # Populate the first word of target sequence with the start word.\n",
    "    target_seq[0, 0] = target_word_index['sostok']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "\n",
    "    while not stop_condition:\n",
    "        (output_tokens, h, c) = decoder_model.predict([target_seq]\n",
    "                + [e_out, e_h, e_c])\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
    "\n",
    "        if sampled_token != 'eostok':\n",
    "            decoded_sentence += ' ' + sampled_token\n",
    "\n",
    "        # Exit condition: either hit max length or find the stop word.\n",
    "        if sampled_token == 'eostok' or len(decoded_sentence.split()) \\\n",
    "            >= max_len_summary - 1:\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1)\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update internal states\n",
    "        (e_h, e_c) = (h, c)\n",
    "\n",
    "    return decoded_sentence"
   ],
   "metadata": {
    "id": "w5F7_yow5Xg8"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# To convert sequence to summary\n",
    "def seq2summary(input_seq):\n",
    "    newString = ''\n",
    "    for i in input_seq:\n",
    "        if i != 0 and i != target_word_index['sostok'] and i \\\n",
    "            != target_word_index['eostok']:\n",
    "            newString = newString + reverse_target_word_index[i] + ' '\n",
    "\n",
    "    return newString\n",
    "\n",
    "\n",
    "# To convert sequence to text\n",
    "def seq2text(input_seq):\n",
    "    newString = ''\n",
    "    for i in input_seq:\n",
    "        if i != 0:\n",
    "            newString = newString + reverse_source_word_index[i] + ' '\n",
    "\n",
    "    return newString"
   ],
   "metadata": {
    "id": "NOETJ5gD5n6a"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for i, news in enumerate(x_test):\n",
    "    if i == 10:\n",
    "        break\n",
    "    print ('Review:', seq2text(news))\n",
    "    print ('Original summary:', seq2summary(y_test[i]))\n",
    "    print ('Predicted summary:', decode_sequence(news.reshape(1,\n",
    "           max_len_content)))\n",
    "    print ('\\n')"
   ],
   "metadata": {
    "id": "tpuxOp4f5tEK",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "32d8ff68-7e07-4ba5-b9d5-04dcf875c028"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}